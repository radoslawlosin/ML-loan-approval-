---
title: "loan_approval_project"
author: "Radosław Łosin"
format: R
editor: RStudio
---

## *Algorytmy uczenia maszynowego w decyzjach kredytowych*

*English title: "Machine learning algorithms in loan approval prediction".*

*Komentarz autora: nomenklatura użyta w niniejszym projekcie będzie zawierała angielskie odpowiedniki z uwagi na uniwersalny charakter przy projektach IT.*

### 1. Cel projektu

Cel projektu to:

-   zdefiniowanie problemu do rozwiązania;

-   przygotowanie bazy danych o kredytobiorcach i zrozumienie zmiennych;

-   przedstawienie i zastosowanie algorytmów uczenia maszynowego nadzorowanego (tzw. supervised machine learning);

-   trening modeli na danych treningowych, a następnie walidacja i optymalizacja modeli;

-   analiza wyników wiarygodności modeli na zbiorze testowych;

-   przeprowadzenie symulacji otrzymania kredytu dla nowych klientów;

-   przedstawienie potencjalnej instytucji finansowej korzyści i ryzyk wynikających z modeli.

Głównym problemem do rozwiązania jest zbudowanie modeli obliczania ryzyka kredytowego na podstawie dostępnej bazy danych o klientach jednego z indyjskich banków. Modele zbudowane w oparciu o algorytmy uczenia maszynowego mają na celu wspomagać bank w zdefiniowaniu ryzykownych kredytobiorców - ograniczenie ryzyka poniesienia strat.

------------------------------------------------------------------------

W pierwszej kolejności ładujemy bibilioteki potrzebne do projektu.

```{r}
pacman::p_load(tidyverse, broom, car, GGally, caret, ISLR, pROC, class, glmnet, vip, randomForest, rpart, rpart.plot, tictoc, ggplot2, dplyr, ggplot2)
options(scipen = 20)
theme_set(theme_bw())
```

### 2. Przygotowanie danych wejściowych

W niniejszej pracy posłużono się ogólno dostępnym zbiorem danych dostępnej na platformie kaggle.com

<https://www.kaggle.com/datasets/krishnaraj30/finance-loan-approval-prediction-data/data?select=train.csv>

Składa się on z 2 części:

-   treningowej (train.csv) - do podzielenia zgodnie z rozdziałem 3, mamy tu kolumnę z decyzją kredytową ;

-   testowej (test.csv) - będzie on potraktowany jako zbiór o nowych klientach, gdyż nie mamy tutaj informacji o decyzji kredytowej.

Wczytujemy zbiór treningowy (train.csv) i od razu usuwamy zbędne kolumny, które nie mają wpływu na udzielenie zdolności kredytowej, np.: Loan_ID. *Uwaga: przy każdym wczytaniu danych train.csv i test.csv na różnych komputerach należy skorygować ścieżkę:*

```{r}
df = read.csv('D://data scientist//projekt//loan approval//raw_data//train.csv'
, na.strings= "",
stringsAsFactors = TRUE
) %>% 
  select(-Loan_ID)
```

Sprawdzamy w których kolumnach pojawiają się komórki "NULL":

```{r}
colSums(is.na(df))
```

Zamieniamy wartości NULL w poszczególnych kolumnach w których wystąpiły:

-   w gender na "Female";

-   Married na Yes;

-   Dependents na 1;

-   Self_Employed na Yes;

-   LoanAmount na średnią;

-   Loan_Amount_Term na średnią;

-   Credit_History na 0 - brak historii kredytowej.

-   Loan_Status z Y/N na 1/0 (factor). Jest to właśnie nasza zmienna celu, która wskazuje czy wnioskodawca kredyt dostał lub nie.

```{r}
df$Gender[is.na(df$Gender)]= "Female"
df$Married[is.na(df$Married)]= "Yes"
df$Dependents[is.na(df$Dependents)]= 1
df$Self_Employed[is.na(df$Self_Employed)]= "Yes"
df$LoanAmount[is.na(df$LoanAmount)] = (mean(df$LoanAmount, na.rm = TRUE))
df$Loan_Amount_Term[is.na(df$Loan_Amount_Term)] = (mean(df$Loan_Amount_Term, na.rm = TRUE))
df$Credit_History[is.na(df$Credit_History)]= 1
df$Loan_Status <- with(df, ifelse(df$Loan_Status == "Y", 1, 0))
df$Loan_Status = as.factor(df$Loan_Status)
table(df$Gender)
table(df$Married)
table(df$Dependents)
table(df$Self_Employed)
table(df$Loan_Amount)
table(df$Loan_Amount_Term)
table(df$Credit_History)
table(df$Loan_Status)
colSums(is.na(df))
summary(df)
```

Po przeanalizowaniu zmiennych należy sprawdzić czy wpływ na decyzję kredytową ma osoba współdzieląca kredyt. Dlatego dodamy kolumnę z informacją czy kredytobiorca jest tylko 1 czy więcej niż 1.

```{r}
df$applicantquantity <- with(df, ifelse(df$CoapplicantIncome == 0, 1, 2))
```

Dodamy kolumnę, która konkretnie wydzieli osoby na utrzymaniu w sposób 0/1. Jeżeli dany kredytobiorca nie ma nikogo na utrzymaniu to damy 0 , jeżeli przynajmniej 1 osoba to należy dać 1.

```{r}
df$anyDependents <- with(df, ifelse(df$Dependents == "0", 0, 1))
```

Aktualnie nasz zbiór df wygląda następująco:

```{r}
df
```

Baza została przygotowana tj. oczyszczona z pustych komórek, a ewentualne istotne zmienne zostały dodane.

### 3. Wyodrębnienie danych treningowych, walidacyjnych i testowych

Kolejnym krokiem jest na podstawie bazy danych (zbiór df) wyodrębnienie podzbioru na dane treningowe, walidacyjne i testowe.

-   Ustalamy losowość dobieranych danych za pomocą set.seed(123);
-   Dane treningowe będą stanowić 75 % zbioru podstawowego (df);
-   Dane do testowania będą stanowić 25 % zbioru (pozostałe, które nie zostały wybrane jako dane treningowe;
-   Wyodrębniamy również dane walidacyjne (df_valid), stanowią one 66% danych treningowych.

```{r}
set.seed(123)
# Wyodrębnienie zbioru treningowego
train_index = sample(
  1:nrow(df)
  , size = floor(0.75 * nrow(df))
)

df_train = df[train_index, ]
df_test = df[-train_index, ]

# Wyodrębnienie zbioru walidacyjnego
train_index2 = sample(
  1:nrow(df_train)
  , size = floor(0.66 * nrow(df_train))
)
# Wyodrębnienie zbioru testowego 

df_valid = df_train[-train_index2, ]
df_train = df_train[train_index2, ]

nrow(df_train) + nrow(df_valid) + nrow(df_test)
```

Sprawdźmy jeszcze zbalansowanie nowych podzbiorów:

```{r}
table(df_train$Loan_Status)
table(df_test$Loan_Status)
table(df_valid$Loan_Status)
```

Stosunek przedstawionych zmiennych 0/1 wynosi ok. 1 do 2 dlatego uznajemy, że zbiór jest zbalansowany.

### 4. Wizualizacja przygotowanych danych

```{r}
boxplot(df$ApplicantIncome,
main = "Wynagrodzenie kredytobiorców",
xlab = "Wynagrodzenie",
col = "orange",
border = "blue",
horizontal = TRUE,
notch = TRUE
)
```

Na powyższym wykresie skrzynkowym (box-plot) widzimy wartości odstające (zarobki ponad 80 tys. rupii przy średniej 5403 i medianie 3812 rupii). Taki wykres skrzynkowy jest małoczytelny z uwagi na zaburzenie wysokimi wartościami.

Przybliżmy wykres wynagrodzenia w postaci histogramu dla limitu 10 tys. rupii.

```{r}
hist(df$ApplicantIncome,
     xlim = c(0, 10000),
xlab = "Wynagrodzenie",
ylab = "Częstość",
breaks = 1000)
```

Wyświetlmy wykres pokazujący wpływ współudziału dodatkowej osoby w kredycie.

```{r}
ggplot(df, aes(x=df$ApplicantIncome, y=df$CoapplicantIncome, alpha=df$Loan_Status)) + geom_point(size = 1, color="blue") + xlim(0, 8000) + ylim(0, 8000) +
    ggtitle("Dochody kredytobiorców") + xlab("Dochód głównego kredytobiorcy") + ylab("Dochód dodatkowej osoby") 
    theme_ipsum()
```

Na podstawie powyższego wykresu można zaobserwować wiele pozytywnych decyzji kredytowych dla osób samotnie zaciągajacych kredyt. Sprawdźmy jak to wygląda w liczbach:

```{r}
q1 <- as.data.frame(which(df$applicantquantity == "2" & df$Loan_Status == "1"))
q2 <- as.data.frame(which(df$applicantquantity == "2" & df$Loan_Status == "0"))
q3 <- as.data.frame(which(df$applicantquantity == "1" & df$Loan_Status == "1"))
q4 <- as.data.frame(which(df$applicantquantity == "1" & df$Loan_Status == "0"))
```

```{r}
nrow(q1)
nrow(q2)
nrow(q3)
nrow(q4)
```

Q1 oznacza zapytanie o kredytobiorców, którzy współdzielą kredyt z dodatkową osobą i otrzymali pozytywną decyzję (245 wnioskodawców);

Q2 to kredytobiorcy, którzy wspóldzielą z dodatkową osobą ale którym odmówiono udzielenia kredytu (96 wnioskodawców);

Q3 to kredytobiorcy samodzielni z pozytywną decyzją (177 wnioskodawców), a Q4 z negatywną (96 wnioskodawców).

### 5. Budowa i trening modelu

Na potrzeby projektu zbuduje modele bazujące na dwóch algorytmach:

-   regresji logistycznej - 3 warianty w celu sprawdzenia responsywności na wprowadzone zmiany (logitstic regresion);

-   lasów losowych (random forest).

Celem treningu modelu jest sprawdzenie jak dane (zmienne) wpływają na prawdopodobieństwo otrzymania kredytu (Loan_Status) która ostatecznie przybiera charakter 0 lub 1.

Poniżej sprawdzamy wpływ każdej zmiennej na wartość Loan_Status (korelacja). Im niższa wartość tym bardziej wpływa na decyzje kredytową. Zbudujemy modele uwzględniające różne dane. Najpierw model logitowy 1, który uwzględnia wszystko - wyłączając starą kolumnę "Dependents", gdyż została ona zaklasyfikowana 0/1 w nowej kolumnie "Any Dependents" i nie mogą jednocześnie koegzystować w modelu. Model trenujemy w oparciu o podzbiór df_train.

#### 5.1. Model logitowy 1

```{r}
model_1 = glm(
  Loan_Status ~ .-Dependents
  , data = df_train
  , family = binomial(link = 'logit')
)

summary(model_1)

```

Największy wpływ ma pozytywna decyzja kredytowa (im mniejsza wartość tym większy wpływ). Kolejny wpływ widać, że dodana przeze mnie kolumna (applicant quantity) określająca ilość aplikujących ma wpływ na udzielenie kredytu. Można to wytłumaczyć tym, że w przypadku śmierci 1 kredytobiorcy pozostaje drugi , to zwiększa wiarygodność a przez to wpływa pozytywnie na decyzję kredytową. Widać również wpływ parametru nieruchomości w niedużym mieście AreaSemiurban - czyli wg definicji na stronie <https://www.rbi.org.in/scripts/bs_viewcontent.aspx?Id=2035> (Indyjskie Rezerwy Bankowe) są to miejscowości o populacji powyżej 10 tys. obywateli i mniej niż 100 tys. obywateli.

Natomiast wpływ zmiennej wprowadzonej "anyDepentends" nie dał dobrych rezultatów. Należy więc jednak usunąć tą zmienną z analizy i zobaczyć, czy poszczególne wartości Dependents mają wpływ. Jednocześnie usuwam z analizy ApplicantIncome gdyż (co ciekawe) ma on nieznaczny wpływ na decyzję kredytową. Można to wytłumaczyć tym, że w banku wniosek o kredyt składają osoby, które już we wczesnej fazie wiedzą czy w ogóle otrzymają kredyt przy swoich dochodach, takie informacje są dostępne nawet w kalkulatorach kredytowych online instytucji finansowych lub po wstępnej konsultacji w banku.

W celu wizualnego przedstawienia wpływu poszczególnych cech na wynik w modelu tworzymy wykresy tzw. " Variable importance plots", co w wolnym tłumaczeniu oznacza wykresy wag poszczególnych cech w modelu:

```{r}
vip(model_1)
```

#### 5.2. Model logitowy 2

Drugi model logitowy nie będzie uwzględniał zmiennej anyDependents i dochodów wnioskodawcy.

```{r}
model_2 = glm(
  Loan_Status ~ .-anyDependents-ApplicantIncome
  , data = df_train
  , family = binomial(link = 'logit')
)

summary(model_2)
```

Widać, iż oprócz historii kredytowej, informacji o dodatkowej osobie w kredycie, duże znaczenie ma informacja o wielkość miasta i o pierwszej osobie na utrzymaniu (Dependents 1). Druga osoba na utrzymaniu też ma dość dobrą korelację (0.34). Najsłabszą korelację (najmniejsze znaczenie) ma długość trwania okresu kredytowania (Loan_Amount_Term wynosi powyżej 0.9) a także płeć kredytobiorcy też powyżej 0.9).

```{r}
vip(model_2)
```

Usuwamy więc z analizy powyższe zmienne i spawdzamy kolejny model 3.

#### 5.3. Model logitowy 3

Trzeci model będzie rozwinięciem modelu 2 - pozbawimy go dodatkowo kolumny Loan_Amount_Term oraz kolumny Gender.

```{r}
model_3 = glm(
  Loan_Status ~ .-anyDependents-ApplicantIncome-Loan_Amount_Term-Gender
  , data = df_train
  , family = binomial(link = 'logit')
)

summary(model_3)
```

Usunięcie kolejnych zmiennych w modelu 3 spowodowało tylko wzmocnienie wpływu parametrów ujętych w modelu 2.

```{r}
vip(model_3)
```

#### 5.4. Model lasu losowego

Do kolejnego modelu zastosowano algorytm tzw. las losowy (ang. Random Forest). Dla tego modelu nie usuwamy żadnej ze zmiennych. Ustawiamy liczbę mtry i liczbę ntree.

```{r}
model_rf = randomForest(
    Loan_Status ~.
    , data = df_train
    , mtry = 4
    , ntree = 1000
  )

summary(model_rf)
 
```

```{r}
vip(model_rf)
```

Przy powyższym modelu nastąpiło kilka znaczących różnic. Historia kredytowa również tutaj ma znaczenie ale nie jest ono tak przeważające nad innymi zmiennymi jak przy regresji logistycznej. Na drugim miejscu wag są dochody wnioskodawcy - co ma racjonalne uzasadnienie, jednakże różni się od założenia przy regresji logistycznej. Trzecią wagą jest wielkość udzielanej pożyczki - co również ma sens. Na czwartym miejscu również jest dochód osoby współpobierającej kredyt. Z punktu widzenia racjonalności wagi w tym modelu są bardziej realne.

### 6. Ocena modeli

Dla każdego z czterech wykonanych modeli przygotowujemy prognozę w oparciu o dane walidacyjne - wyodrębnione wcześniej jako zbiór df_valid. Korzystamy z funkcji predict dla każdego modelu oddzielnie.

```{r}
y_hat_prob_1 = predict(model_1, newdata = df_valid, type = 'response')

y_hat_prob_2 = predict(model_2, newdata = df_valid, type = 'response')

y_hat_prob_3 = predict(model_3, newdata = df_valid, type = 'response')

y_hat_prob_4 = predict(model_rf, newdata = df_valid, type ='response')
```

Następnie oglądamy przykładowe wyniki dla y_hat_1 i y_hat4.

```{r}
y_hat_prob_1
y_hat_prob_4
```

W y_hat_1 (model logitowy 1) lewa kolumna oznacza nr zmiennej ze zbioru df_valid, dla której została wyliczona prognoza. Prawa kolumna jest wynikiem prognozy o typie danych 'double' - czyli liczba niecałkowita. Natomiast y_hat_4 na podstawie lasu losowego już podaje domyślnie wynik 0/1. Z uwagi na to, iż nasz model musi operować na informacji czy dany kredytobiorca uzyska kredyt lub nie musimy nadać naszym wynikom z modeli logitowych wartości 0 lub 1. Otrzymamy to za pomocą funkcji ifelse na naszych zbiorach y_hat i to do nas należy ustalenie progu (threshold) kiedy ma być 0 a kiedy 1. Ustalamy, że jeżeli wynik jest większy niż 0.5 to wówczas przyjmie 1, a jeżeli będzie równy bądź mniejszy od 0.5 wówczas będzie miała wartość 0.

```{r}
y_hat_1 = ifelse(y_hat_prob_1 > 0.50, "1", "0") %>% as.factor()
y_hat_2 = ifelse(y_hat_prob_2 > 0.50, "1", "0") %>% as.factor()
y_hat_3 = ifelse(y_hat_prob_3 > 0.50, "1", "0") %>% as.factor()
y_hat_4 = ifelse(y_hat_prob_4 == 0, "0", "1") %>% as.factor()

```

Wartości zostały wprowadzone do pamięci podręcznej i przykładowo wyświetlimy y_hat_1.

```{r}
y_hat_1
```

Widać, że wartości są aktualnie 0 lub 1. Jak porównać te wartości z danymi walidacyjnymi czyli innymi słowy jak nasze prognozy mają się do rzeczywistości?

W oparciu o poniższy kod tworzymy tzw. tabelę kontyngencji (macierz), która ma na celu porównanie trafności wyników Loan_Status zbioru walidacyjnego i prognozowanego (y_hat) i określenie jak nasze modele się sprawdzają:

```{r}
cf1 <- confusionMatrix(
  data = y_hat_1
  , reference = df_valid$Loan_Status
  , positive = "1"
)

cf2 <- confusionMatrix(
  data = y_hat_2
  , reference = df_valid$Loan_Status
  , positive = "1"
) 

cf3 <- confusionMatrix(
  data = y_hat_3
  , reference = df_valid$Loan_Status
  , positive = "1"
) 

cf4 <- confusionMatrix(
  data = y_hat_4
  , reference = df_valid$Loan_Status
  , positive = "1"
)
```

Jak najszybciej określić dokładność (accuracy) modeli? Za pomocą poniższego kodu:

```{r}
confusionMatrix(y_hat_1, df_valid$Loan_Status)$overall[1]
confusionMatrix(y_hat_2, df_valid$Loan_Status)$overall[1]
confusionMatrix(y_hat_3, df_valid$Loan_Status)$overall[1]
confusionMatrix(y_hat_4, df_valid$Loan_Status)$overall[1]
```

Model 1 ma nieco niższą dokładność, natomiast 2 i 3 mają tą samą dokładność 80%. Jednakże model 3 korzysta z dwóch zmiennych mniej niż model 2 dlatego lepiej z niego korzystać z uwagi na potencjalnie niższy koszt pozyskiwania danych i czas trwania obliczeń przy większych zbiorach danych. Model 4 oparty na lasach losowych, ma najmniejszą dokładność (76%). Sprawdźmy pozostałe parametry:

```{r}
confusionMatrix(y_hat_1, df_valid$Loan_Status, positive = "1")
confusionMatrix(y_hat_2, df_valid$Loan_Status, positive = "1")
confusionMatrix(y_hat_3, df_valid$Loan_Status, positive = "1")
confusionMatrix(y_hat_4, df_valid$Loan_Status, positive = "1")
```

#### 6.1. Wyjaśnienie macierzy kontyngencji.

Co oznaczają powyższe dane ? Przyjżyjmy się bliżej poniższej tabeli dla modelu 1.

![](images/clipboard-4119068688.png){width="165"}

Powyższa tabela to tzw. Macierz Kontyngencji (Confusion Matrix). Co oznaczają poszczególne wartości? Jest to tabela, która porównuje wyniki modelu opartego na zbiorze treningowym z rzeczywistymi wartościami zbioru walidacyjnego, w tym wypadku:

-   (1.1 - True positive) 103 osób (65%) - faktycznie uzyskało kredyt i model też tak przewidział właściwe udzielenie kredytu;

-   (0.0 - True negative) 22 osób (14%) faktycznie nie uzyskało kredytu i model też to przewidział (właściwe nieudzielenie kredytu):

-   (0.1 - False negative) 2 osób (2%) nie otrzymałoby kredytu przez prognozę mimo, że faktycznie go otrzymała - fałszywy alarm lub niewłaściwe nieudzielenie kredytu;

-   (1.0 - False positive) 30 osób (19%) otrzymało kredyt od modelu ale faktycznie nie powinna go dostać, czyli są to osoby szczególnie niebezpieczne z punktu widzenia kredytodawcy - niewłaściwe udzielenie kredytu.

    Łącznie z tej grupy testowej 125 na 157 osób właściwie zostały określone przez model (80%), ale 32 osób błędnie, szczególnie te 30 gdzie nadano kredyt mimo, że nie były wiarygodne. Dlatego, trzeba starać się wyeliminować ten błąd. W naszym zestawieniu modelu błąd jest zdefiniowany pod nazwą "Specificity" - specyfikacja. W naszym modelu wynosi Specyfikacja wynosi tylko 44%. Przeanalizujmy pozostałe modele w celu określenia specyfikacji:

```{r}
# Model 1

con_matrx1 <- table(reality = df_valid$Loan_Status, prediction = y_hat_1)

hm1 <- as.data.frame(as.table(con_matrx1))

plot <- ggplot(hm1, aes(x = prediction, y = reality, fill = Freq)) + 
  geom_tile() + theme_bw() + coord_equal() +
  scale_fill_distiller(palette = "Blues", direction = 1) +
  guides(fill = FALSE) +
  geom_text(aes(label = Freq), color = "black", size = 10)

plot + 
  scale_x_discrete(limits = c("0", "1"),
                    labels = c("negative", "positive")) +
  scale_y_discrete(limits = c("0", "1"),
                    labels = c("negative", "positive")) +
  theme(axis.text.x = element_text(size = 20),
        axis.text.y = element_text(size = 20),
        axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20))
  
  
```

```{r}

# Model 2 

con_matrx2 <- table(reality = df_valid$Loan_Status, prediction = y_hat_2)

hm2 <- as.data.frame(as.table(con_matrx2))

plot <- ggplot(hm2, aes(x = prediction, y = reality, fill = Freq)) + 
  geom_tile() + theme_bw() + coord_equal() +
  scale_fill_distiller(palette = "Blues", direction = 1) +
  guides(fill = FALSE) +
  geom_text(aes(label = Freq), color = "black", size = 10)

plot + 
  scale_x_discrete(limits = c("0", "1"),
                    labels = c("negative", "positive")) +
  scale_y_discrete(limits = c("0", "1"),
                    labels = c("negative", "positive")) +
  theme(axis.text.x = element_text(size = 20),
        axis.text.y = element_text(size = 20),
        axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20))
```

```{r}

# Model 3

con_matrx3 <- table(reality = df_valid$Loan_Status, prediction = y_hat_3)

hm3 <- as.data.frame(as.table(con_matrx3))

plot <- ggplot(hm3, aes(x = prediction, y = reality, fill = Freq)) + 
  geom_tile() + theme_bw() + coord_equal() +
  scale_fill_distiller(palette = "Blues", direction = 1) +
  guides(fill = FALSE) +
  geom_text(aes(label = Freq), color = "black", size = 10)

plot + 
  scale_x_discrete(limits = c("0", "1"),
                    labels = c("negative", "positive")) +
  scale_y_discrete(limits = c("0", "1"),
                    labels = c("negative", "positive")) +
  theme(axis.text.x = element_text(size = 20),
        axis.text.y = element_text(size = 20),
        axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20))
```

```{r}

# Model 4 

con_matrx4 <- table(reality = df_valid$Loan_Status, prediction = y_hat_4)

hm4 <- as.data.frame(as.table(con_matrx4))

plot <- ggplot(hm4, aes(x = prediction, y = reality, fill = Freq)) + 
  geom_tile() + theme_bw() + coord_equal() +
  scale_fill_distiller(palette = "Blues", direction = 1) +
  guides(fill = FALSE) +
  geom_text(aes(label = Freq), color = "black", size = 10)

plot + 
  scale_x_discrete(limits = c("0", "1"),
                    labels = c("negative", "positive")) +
  scale_y_discrete(limits = c("0", "1"),
                    labels = c("negative", "positive")) +
  theme(axis.text.x = element_text(size = 20),
        axis.text.y = element_text(size = 20),
        axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20))
```

Model 1

![](images/clipboard-771795697.png){width="163"}

------------------------------------------------------------------------

Model 2

![](images/clipboard-1717435807.png){width="167"}

------------------------------------------------------------------------

Model 3

![](images/clipboard-3518847878.png){width="154"}

------------------------------------------------------------------------

Model 4

![](images/clipboard-2563725918.png){width="164"}

Wyniki są zbliżone, jednakże do dalszej analizy i modyfikacji specyfikacji posłużymy się modelem 3.

#### 6.2. Finalna ocena modeli na zbiorze testowym.

Spróbujmy polepszyć specyfikację poprzez podniesienie progu (threshold) modelu 3 z 0.51 do 0.7.

```{r}
y_hat_prob_3b = predict(
  model_3
  , newdata = df_test
  , type = 'response'
  
)

y_hat_3b = ifelse(y_hat_prob_3b > 0.70, 1, 0) %>% as.factor()

confusionMatrix(y_hat_3b, df_test$Loan_Status, positive = "1")
confusionMatrix(y_hat_3b, df_test$Loan_Status)$overall[1]
```

Na zbiorze testowym zwiększenie progu zmniejszyło dokładność modelu z 84% do 78%. Sensitivity (czułość) spadła do 82%. Jednakże model zachował się bezpiecznie (surowo) gdyż specyfikacja wzrosła z 51 do 67.5%. Z jednej strony udzielonych zostanie mniej kredytów kredytobiorcom, którzy do tej pory mieli tą decyzję pozytywną (strata banku), a z drugiej strony bank nie udzieli kredytu ryzykownym klientom (było 29 a teraz 14).

To samo obliczenie dla zbioru testowego wykonujemy dla algorytmu lasu losowego:

```{r}
y_hat_prob_rf = predict(
  model_rf
  , newdata = df_test
  , type = 'prob'
  
)

y_hat_prob_rf2 <- y_hat_prob_rf[, -1]
y_hat_rf = ifelse(y_hat_prob_rf2 > 0.5, 1, 0) %>% as.factor()

confusionMatrix(y_hat_rf, df_test$Loan_Status, positive = "1")
confusionMatrix(y_hat_rf, df_test$Loan_Status)$overall[1]
```

Model lasu losowego przeliczony dla zbioru testowego dał bardzo dobre wyniki tj. dokładność na poziomie 83% czułość 94% i specyfikację na poziomie 53%. Macierz kontyngencji wskazuje co prawda udzielenie kredytu 20 ryzykownym osobom, ale model udzieli kredytu dla większej ilości osób (105) i zmniejszy ilość osób wiarygodnych dla których model nie dałby pozytywnej decyzji (6).

#### 6.3. Wizualizacja wyników modelu.

Wykres ROC przedstawia stosunek TPR do FPR:

```{r}
roc = data.frame(
  threshold = seq(0, 1, by = 0.01)
  , TPR = NA
  , FPR = NA
)

for (i in 1:nrow(roc)) {
  y_hat_3b = ifelse(
    y_hat_prob_3b > roc$threshold[i]
    , '1'
    , '0'
  ) %>% as.factor()
  
  conf_matrix_logit = table(df_test$Loan_Status, y_hat_3b) %>% as.matrix()
  
  roc$FPR[i] = conf_matrix_logit[2,1] / sum(conf_matrix_logit[1, ])
  roc$TPR[i] = conf_matrix_logit[1,1] / sum(conf_matrix_logit[1, ])
  
}

ggplot(roc, aes(x = FPR, y = TPR)) +
  geom_point()
```

Interpretacja jest następująca: model jest tym lepszy, im bardziej widoczne punkty odbiegają od prostej stanowiącej przekątną tego wykresu.

```{r}
roc_2 = pROC::roc(
  df_test$Loan_Status
  , y_hat_prob_3b
)

plot(roc_2) 

pROC::auc(roc_2)
```

Pole pod krzywą wynosi 0.8102, im wynik bliżej 1 tym model jest lepszy.

Dla modelu lasu losowego wygląda to następująco:

```{r}
roc_3 = data.frame(
  threshold = seq(0, 1, by = 0.01)
  , TPR = NA
  , FPR = NA
)

for (i in 1:nrow(roc_3)) {
  y_hat_rf = ifelse(
    y_hat_prob_rf2 > roc_3$threshold[i]
    , '1'
    , '0'
  ) %>% as.factor()
  
  conf_matrix_rf = table(df_test$Loan_Status, y_hat_rf) %>% as.matrix()
  
  roc$FPR[i] = conf_matrix_rf[2,1] / sum(conf_matrix_rf[1, ])
  roc$TPR[i] = conf_matrix_rf[1,1] / sum(conf_matrix_rf[1, ])
  
}

ggplot(roc, aes(x = FPR, y = TPR)) +
  geom_point()
  
```

```{r}
roc_4 = pROC::roc(
  df_test$Loan_Status
  , y_hat_prob_rf2
)

plot(roc_4) 

pROC::auc(roc_4)
```

Wyniki dla lasu losowego są nieco gorsze, pole pod wykresem wynosi 0.7563.

### 7. Prognozowanie wyników.

Jako finalny produkt pracy przygotujemy nowe decyzje kredytowe w oparciu o zbiór "test.csv" zawierający dane o nowych klientach. W pierwszej kolejności analogicznie wczytujemy i porządkujemy nowy zestaw danych.

```{r}
df_newdata = read.csv('D://data scientist//projekt//loan approval//raw_data//test.csv'
, na.strings= "", sep = ";",
stringsAsFactors = TRUE
) %>% 
  select(-Loan_ID)
View(df_newdata)
```

```{r}
colSums(is.na(df_newdata))
```

```{r}
df_newdata$Gender[is.na(df_newdata$Gender)]= "Female"
df_newdata$Dependents[is.na(df_newdata$Dependents)]= 1
df_newdata$Self_Employed[is.na(df_newdata$Self_Employed)]= "Yes"
df_newdata$LoanAmount[is.na(df_newdata$LoanAmount)] = (mean(df_newdata$LoanAmount, na.rm = TRUE))
df_newdata$Loan_Amount_Term[is.na(df_newdata$Loan_Amount_Term)] = (mean(df_newdata$Loan_Amount_Term, na.rm = TRUE))
df_newdata$Credit_History[is.na(df_newdata$Credit_History)]= 1
table(df_newdata$Gender)
table(df_newdata$Married)
table(df_newdata$Dependents)
table(df_newdata$Self_Employed)
table(df_newdata$Loan_Amount)
table(df_newdata$Loan_Amount_Term)
table(df_newdata$Credit_History)
colSums(is.na(df_newdata))
summary(df_newdata)
```

Sprawdzamy ponownie ilość danych NA.

```{r}
colSums(is.na(df_newdata))
```

Analogicznie jak w rozdziale 2 "Przygotowanie danych" dodajemy kolumny.

```{r}
df_newdata$applicantquantity <- with(df_newdata, ifelse(df_newdata$CoapplicantIncome == 0, 1, 2))
```

```{r}
df_newdata$anyDependents <- with(df_newdata, ifelse(df_newdata$Dependents == "0", 0, 1))
```

Wykonujemy obliczenia i zapisujemy wynik decyzji do nowych kolumn w zbiorze df_newdata pod 2 nowymi kolumnami, jedna kolumna dla modelu logitowego, druga dla modelu lasu losowego:

```{r}
y_hat_prob_logit_new = predict(model_3, newdata = df_newdata, type="response")

df_newdata$Loan_Status_logit_new <- with(df_newdata, ifelse    (y_hat_prob_logit_new > 0.7, 1, 0)) %>% as.factor()

y_hat_prob_rf_new = predict(model_rf, newdata = df_newdata, type="response")

df_newdata$Loan_Status_rf_new <- with(df_newdata, ifelse    (y_hat_prob_rf_new == 0, 0, 1)) %>% as.factor()
```

Wyświetlamy tablicę dla dwóch modeli, na których możemy odczytać ile decyzji kredytowych było negatywnych a ile pozytywnych dla każdego z modelu.

```{r}
table(df_newdata$Loan_Status_logit_new)
table(df_newdata$Loan_Status_rf_new)
```

Na diagramie wygląda to w następujący sposób:

```{r}
colors = c("#7fba81", "#f01111")
modeltype <- c("Regresja logistyczna", "Las losowy")
decyzje <- c("pozytyw", "odmowa")
 
# Create the matrix of the values.
Values <- matrix(c(242, 292, 125, 75),
                nrow = 2, ncol = 2, byrow = TRUE)
 
barplot(Values, main = "Decyzje kredytowe w zależności od modelu", names.arg = modeltype,
        xlab = "Typ modelu", ylab = "Liczba decyzji", col = colors, width = 0.4)
 
legend("center", decyzje, cex = 0.7, fill = colors)
```

### 8. Porównanie wyników i wnioski

Wnioski:

-   Osiagnięto cel pracy, gdyż za pomocą 2 różnych algorytmów uczenia maszynowego można zaproponować instytucji finansowej 2 opcjonalne produkty obliczania zdolności kredytowej: model oparty na regresji logistycznej i model oparty na lesie losowym.

-   Badane modele różnią się ocenami wag poszczególnych zmiennych. Dla lasu losowego kryteria te wydają się bardziej racjonalne - odpowiadają najczęstszym kryteriom banków przy udzielaniu kredytu.

-   Dla modelu lasu losowego dla nowych danych udzielono więcej pozytywnych decyzji kredytowych niż dla modelu regresji logistycznej (292 vs 242) i odpowiednio było mniej odmów (75 vs 125 dla modelu logitowego).

-   Model lasu losowego wydaje się mniej ostrożny, ale zdecydowanie zwiększa ewentualną pulę klientów - co stanowi potencjalny zysk dla banku.

-   Decyzje kredytowe oparte na modelu lasów losowych zwiększają dostępność do otrzymania kredytu przez wnioskodawcę.

-   Do dalszej analizy ryzyka kredytowego wydaje się zasadne szczegółowe przebadanie przypadków wnioskodawców, które w tych 2 modelach nie otrzymałyby pozytywnej decyzji kredytowej.

Koniec pliku.
